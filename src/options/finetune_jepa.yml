name: finetune_jepa_resnet18_cifar10
seed: 42

# Path to pretrained I-JEPA checkpoint
pretrain_path: checkpoints/jepa_resnet18_cifar10_best.pth
checkpoint_path: /checkpoints

# Model configuration
backbone:
  name: resnet18  # Must match the pretrained model

input_size: 224  # Must match pretraining size
out_nc: 10  # CIFAR-10 classes
freeze_backbone: true  # Set to true for linear evaluation, false for full fine-tuning

# Training hyperparameters
hyperparameters:
  lr: 0.01  # Higher LR for linear eval, lower (0.001) for fine-tuning
  epochs: 100
  weight_decay: 1e-4
  beta1: 0.9
  beta2: 0.999
  eta_min: 0.0001
  seed: 42

  validate_mode: epoch
  validate_step_freq: 100
  validate_epochs_freq: 1

# Dataset configuration (CIFAR-10)
datasets:
  train:
    mode: cifar10
    phase: train
    dataroot: /mnt/disk1/huync/Self-Supervised-Learning-comparisons/datasets
    batch_size: 128
    n_workers: 4

  val:
    mode: cifar10
    phase: val
    dataroot: /mnt/disk1/huync/Self-Supervised-Learning-comparisons/datasets
    batch_size: 256
    n_workers: 4

  test:
    mode: cifar10
    phase: test
    dataroot: /mnt/disk1/huync/Self-Supervised-Learning-comparisons/datasets
    batch_size: 256
    n_workers: 4
